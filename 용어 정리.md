# **Python**

## **머신러닝**

**GradientDescent**

```python
#기본 방법
learning_rate = 0.1
gradient = tf.reduce_mean((hypothesis-Y)*X)
descent = W - learning_rate * gradient
update = W.assign(descent)
#간편한 방법
optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)
train = optimizer.minimize(cost)
```

**Session**

머신 러닝은 graph로 표현되는데, 이는 Session 내에서 실행된다. 

**global_variables_initializer()**

Session 돌리는데 항상 초기화 시켜줘야함.

 **placeholder**

python에서 빈 list 객체 생성처럼 러닝을 위해 tensorflow에서 생성

만약 다변수 회귀를 실행하면 shape 설정 해줘야함

**zeros**

**GradientDescentOptimizer**

```python
optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)
train = optimizer.minimize(cost)
```

cost(loss)값을 최소화 학습을 위해서 복잡한 미분 식을 직접 작성하는 수고를 덜어줌.

>  compute_gradient
>
> ​	cost에 맞는 gradient 계산해 설정
>
> apply_gradient
>
> ​	설정한 gradient를 optimizer에 실제 설정해줌

**batch**

train 시킬때 data 범위와 크기 설정

**coordinator & thread**

스레드를 관리해주기 위한 공간인 코디네이터를 생성